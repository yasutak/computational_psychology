{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Computational Modeling of Behavioral Data by Prof. Kentaro Katahira\n\n## Rescorla-Wagner model"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Plots\nusing Interact\n\n\"\"\"\nNâ‚œ: number of trials\nÎ±: learning rate\nPáµ£: probability of getting reward\n\"\"\"\n\n@manipulate for Nâ‚œ = 0:1:500, Î± = 0:0.05:1, Páµ£ = 0:0.05:1\n\n    ğ• = zeros(Nâ‚œ) #strengths of association as Nâ‚œ-length vector\n    ğ‘ = rand(Nâ‚œ) .< Páµ£ # presence of reinforcement (1 or 0) as Nâ‚œ-length vector\n\n    for t in 1: Nâ‚œ-1\n\n        ğ•[t+1] = ğ•[t] + Î± *(ğ‘[t]-ğ•[t])\n    end\n\n    plot(ğ•, label= string(\"a \", Î±))\n    plot!([(i, Páµ£) for i in 1:1:Nâ‚œ], label=\"expected value of r: \" * string(Páµ£))\n    xlabel!(\"number of trials\")\n    ylabel!(\"strength of association\")\n    ylims!((0, 1))\n    title!(\"Rescorla-Wagner model\")\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q-learning simulation\n\n\n### softmax function"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function softmax(Î², Î”q)\n    return 1 / (1+ exp(-Î² * (Î”q)))\nend\n\n@manipulate for Î² in 0:0.05:5\n    plot([(Î”q, softmax(Î², Î”q)) for Î”q in -4:0.1:4], m=:o, label=string(\"beta \", Î²))\n    xlabel!(\"difference in Q\")\n    ylabel!(\"probability\")\n    ylims!((0, 1))\n    title!(\"Softmax Function\")\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### interactive plot of Q-learning model"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"\"\"\nNâ‚œ: number of trials\nÎ±: learning rate\nÎ²: inverse temperature\nPáµ£: probability of getting reward in A\n\"\"\"\n\n@manipulate for Nâ‚œ in 0:5:200, Î± in 0:0.05:1, Î² in 0:0.25:5, Páµ£ in 0:0.05:1\n\n    ğ = zeros((2, Nâ‚œ)) #initial value of Q in 2 by Nâ‚œ matrix\n    ğœ = zeros(Int, Nâ‚œ) #initial choice in each Nâ‚œ trial\n    ğ« = zeros(Nâ‚œ) # 0 (no reward) or 1 (reward) in each Nâ‚œ trial\n    Pâ‚ = zeros(Nâ‚œ) # probability of choosing A in each trial\n    P = (Páµ£, 1-Páµ£)\n\n    for t in 1:Nâ‚œ-1\n        Pâ‚ = softmax(Î², ğ[1, t] - ğ[2, t])\n\n        if rand() < Pâ‚\n            ğœ[t] = 1 #choose A\n            ğ«[t] = Int(rand(Float64) < P[1])\n        else\n            ğœ[t] = 2 #choose B\n            ğ«[t] = Int(rand(Float64) < P[2])\n        end\n\n        ğ[ğœ[t], t+1] = ğ[ğœ[t], t] + Î± * (ğ«[t] - ğ[ğœ[t], t])\n        ğ[3 - ğœ[t], t+1] = ğ[3 - ğœ[t], t] # retain value of unpicked choice\n    end\n\n    plot(ğ[1, :], label=\"Qt(A)\", color=\"orange\")\n    plot!([(i, P[1]) for i in 1:1:Nâ‚œ], label=\"expected value of reward for A:\" * string(P[1]), color=\"darkorange\")\n    plot!(ğ[2, :], label=\"Qt(B)\", color=\"skyblue\")\n    plot!([(i, P[2]) for i in 1:1:Nâ‚œ], label=\"expected value of reward for B:\" * string(P[2]), color=\"darkblue\")\n    xlabel!(\"number of trials\")\n    ylabel!(\"Q (value of behavior?)\")\n    ylims!((0, 1))\n    title!(\"Q-learning model\")\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameter Estimation\n\n### Optimization with Optim package"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"\"\"\nThis function returns a vector of choices and a vector of rewards, both of which will be used for parameter estimation\n\"\"\"\n\nfunction generate_qlearning_data(Nâ‚œ, Î±, Î², Páµ£)\n\n    ğ = zeros((2, Nâ‚œ)) #initial value of Q in 2 by Nâ‚œ matrix\n    ğœ = zeros(Int, Nâ‚œ) #initial choice in each Nâ‚œ trial\n    ğ« = zeros(Nâ‚œ) # 0 (no reward) or 1 (reward) in each Nâ‚œ trial\n    Pâ‚ = zeros(Nâ‚œ) # probability of choosing A in each trial\n    P = (Páµ£, 1-Páµ£)\n\n    for t in 1:Nâ‚œ-1\n        Pâ‚ = softmax(Î², ğ[1, t] - ğ[2, t])\n\n        if rand() < Pâ‚\n            ğœ[t] = 1 #choose A\n            ğ«[t] = (rand(Float64) < P[1])\n        else\n            ğœ[t] = 2 #choose B\n            ğ«[t] = Int(rand(Float64) < P[2])\n        end\n\n        ğ[ğœ[t], t+1] = ğ[ğœ[t], t] + Î± * (ğ«[t] - ğ[ğœ[t], t])\n        ğ[3 - ğœ[t], t+1] = ğ[3 - ğœ[t], t] # retain value of unpicked choice\n    end\n\n    return ğœ, ğ«\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"\"\"\ninit_values: [Î±, Î²]\nÎ±: learning rate\nÎ²: inverse temperature\nğœ: vector of choices in each Nâ‚œ trial in 1(A) or 2(B)\nğ«: 0 (no reward) or 1 (reward) in each Nâ‚œ trial\n\n\"\"\"\n\nfunction func_qlearning(init_values, ğœ, ğ«) #needed for parameters to be passed as list for Optim package\n\n    Nâ‚œ = length(ğœ)\n    Pâ‚ = zeros(Nâ‚œ) #probabilities of selecting A\n    ğ = zeros((2, Nâ‚œ))\n    logl = 0 #initial value of log likelihood\n\n    for t in 1:Nâ‚œ - 1\n        Pâ‚ = softmax(init_values[2], ğ[1, t] - ğ[2, t])\n        logl += (ğœ[t] == 1) * log(Pâ‚) + (ğœ[t] == 2) * log(1 - Pâ‚)\n        ğ[ğœ[t], t + 1] = ğ[ğœ[t], t] + init_values[1] * (ğ«[t] - ğ[ğœ[t], t])\n        ğ[3 - ğœ[t], t + 1] =  ğ[3 - ğœ[t], t]\n    end\n\n    return (negll = -logl, ğ = ğ, Pâ‚ = Pâ‚);\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Optim\n\n@manipulate for Nâ‚œ in 0:5:200, Î± in 0:0.05:1, Î² in 0:0.25:5, Páµ£ in 0:0.05:1\n    ğœ, ğ« = generate_qlearning_data(Nâ‚œ, Î±, Î², Páµ£)\n\n    func_qlearning_opt(init_values) = func_qlearning(init_values, ğœ, ğ«).negll\n\n    initial_values = rand(2)\n    lower = [0.0, 0.0]\n    upper = [1.0, 5.0]\n    inner_optimizer = GradientDescent()\n    results = optimize(func_qlearning_opt, lower, upper, initial_values, Fminbox(inner_optimizer));\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### optimization with BlackBoxOptim package"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using BlackBoxOptim\n\n@manipulate for Nâ‚œ in 0:5:200, Î± in 0:0.05:1, Î² in 0:0.25:5, Páµ£ in 0:0.05:1\n    ğœ, ğ« = generate_qlearning_data(Nâ‚œ, Î±, Î², Páµ£)\n    \n    func_qlearning_opt(init_values) = func_qlearning(init_values, ğœ, ğ«).negll\n\n    results = bboptimize(func_qlearning_opt; SearchRange = [(0.0, 1.0), (0.0, 5.0)], NumDimensions = 2);\n    best_candidate(results)\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also compare performances when using different optimizers."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "func_qlearning_opt(init_values) = func_qlearning([0.3, 0.4], ğœ, ğ«).negll\ncompare_optimizers(func_qlearning_opt; SearchRange = [(0.0, 1.0), (0.0, 5.0)], NumDimensions = 2);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### optimization with JuMP and Ipopt packages"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "#The following code block generates error. How can I fix it?\n\nusing JuMP, Ipopt, ForwardDiff\n\nğœ, ğ« = generate_qlearning_data(50, 0.6, 0.7, 0.5)\n\nfunc_qlearning_JuMP(Î±, Î²) = func_qlearning((Î±, Î²), ğœ, ğ«).negll #JuMP needs separate variables, not a list\n\nm = Model(Ipopt.Optimizer)\nregister(m, :func_qlearning_JuMP, 2, func_qlearning_JuMP, autodiff=true)\n\n@variable(m, 0.0 <= x <= 1.0, start=rand())\n@variable(m, 0.0 <= y <= 5.0, start=5*rand())\n@NLobjective(m, Min, func_qlearning_JuMP(x, y))\n@show optimize!(m)\nprintln(\"Î± = \", value(x), \" Î² = \", value(y))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {},
      "execution_count": null
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.4.1"
    },
    "kernelspec": {
      "name": "julia-1.4",
      "display_name": "Julia 1.4.1",
      "language": "julia"
    }
  },
  "nbformat": 4
}
